{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://people.eecs.berkeley.edu/~taesung_park/CycleGAN/datasets/summer2winter_yosemite.zip\n",
    "#!unzip summer2winter_yosemite.zip\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms \n",
    "import torch.utils.data as Data\n",
    "import torchvision.transforms as T\n",
    "from glob import glob\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "from torchvision.utils import save_image\n",
    "import time\n",
    "%matplotlib inline\n",
    "\n",
    "# from torchsummary import summary\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "to_img= T.Compose([T.ToPILImage()])\n",
    "to_tensor = T.Compose([T.ToTensor()])\n",
    "load_norm = T.Compose([T.ToTensor(),T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "class Parser():\n",
    "    #hyperparameters\n",
    "    def __init__(self):\n",
    "        #image setting\n",
    "        self.n_epoch = 50\n",
    "        self.batch_size = 1\n",
    "        self.lr = 0.0002\n",
    "        self.b1 = 0.9\n",
    "        self.b2 = 0.999\n",
    "        self.img_size = 128\n",
    "        self.lam1 = 10\n",
    "        self.lam2 = 5\n",
    "        self.model_save_freq = 1000\n",
    "        self.img_save_freq = 100\n",
    "        self.show_freq = 50\n",
    "        self.model_path = './CycleGAN0704-Normal/Model/'\n",
    "        self.img_path = './CycleGAN0704-Normal/Image/' \n",
    "        self.conv_dim = 64\n",
    "        self.n_res = 9\n",
    "        self.D_out_dim = 1\n",
    "        \n",
    "args = Parser()\n",
    "\n",
    "if not os.path.exists(args.model_path):\n",
    "    os.makedirs(args.model_path)\n",
    "if not os.path.exists(args.img_path):\n",
    "    os.makedirs(args.img_path)\n",
    "\n",
    "class WeatherDataset(Data.Dataset):\n",
    "    def __init__(self, mode='train', args=None):\n",
    "        \n",
    "        self.image_transform = T.Compose([\n",
    "            #T.RandomResizedCrop(args.img_size, scale=(0.3,1.0)),\n",
    "            T.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        ])\n",
    "        if mode == 'train':\n",
    "            self.summer_files = sorted(glob('./data/summer2winter/trainA/*.jpg'))\n",
    "            self.winter_files = sorted(glob('./data/summer2winter/trainB/*.jpg'))\n",
    "        else:\n",
    "            self.summer_files = sorted(glob('./data/summer2winter/testA/*.jpg'))\n",
    "            self.winter_files = sorted(glob('./data/summer2winter/testB/*.jpg'))\n",
    "        print('Loaded')\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        summer_img = self.image_transform(Image.open(self.summer_files[index % len(self.summer_files)]))\n",
    "        winter_img = self.image_transform(Image.open(self.winter_files[index % len(self.winter_files)]))\n",
    "        \n",
    "        return summer_img, winter_img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.summer_files)\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_features, eps=1e-5, affine=True):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.num_features = num_features\n",
    "        self.affine = affine\n",
    "        self.eps = eps\n",
    "        \n",
    "        if self.affine:\n",
    "            self.gamma = nn.Parameter(torch.Tensor(num_features).uniform_()) # num_featurs, depth\n",
    "            self.beta = nn.Parameter(torch.zeros(num_features))\n",
    "\n",
    "    def forward(self, x):\n",
    "        shape = [-1] + [1] * (x.dim() - 1)\n",
    "        mean = x.view(x.size(0), -1).mean(1).view(shape)\n",
    "        std = x.view(x.size(0), -1).std(1).view(shape)\n",
    "        y = (x - mean) / (std + self.eps)\n",
    "        if self.affine:\n",
    "            a_shape = [1, -1] + [1] * (x.dim() - 2)\n",
    "            y = self.gamma.view(a_shape) * y + self.beta.view(a_shape)\n",
    "        return y\n",
    "    \n",
    "class Flatten(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(Flatten, self).__init__()\n",
    "    def forward(self,x):\n",
    "        return x.view(x.size(0),-1)\n",
    "    \n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(dim,dim,3,1,0),\n",
    "            nn.InstanceNorm2d(dim),\n",
    "            nn.LeakyReLU(0.2,inplace=True),\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(dim,dim,3,1,0),\n",
    "            nn.InstanceNorm2d(dim),\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        return nn.LeakyReLU(0.2,inplace=True)(self.model(x) + x)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "class UpBlock(nn.Module):\n",
    "    def __init__(self,in_dim,out_dim):\n",
    "        super(UpBlock, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(in_dim,out_dim,3,1,1),\n",
    "            nn.InstanceNorm2d(out_dim),\n",
    "            nn.LeakyReLU(0.2,inplace=True)\n",
    "                                  )\n",
    "    def forward(self,x):\n",
    "        return self.model(x)\n",
    "        \n",
    "        \n",
    "\n",
    "    \n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, dim = 32, num_res = 6):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        res_seq = nn.ModuleList()\n",
    "        res_seq.extend([ResBlock(dim*4) for i in range(num_res)])\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.ReflectionPad2d(3),\n",
    "            nn.Conv2d(3,dim,7,1,0),\n",
    "            nn.InstanceNorm2d(dim),\n",
    "            nn.LeakyReLU(0.2,inplace=True),\n",
    "            nn.Conv2d(dim,dim*2,3,2,1),\n",
    "            nn.InstanceNorm2d(dim*2),\n",
    "            nn.LeakyReLU(0.2,inplace=True),\n",
    "            nn.Conv2d(dim*2,dim*4,3,2,1),\n",
    "            nn.InstanceNorm2d(dim*4),\n",
    "            nn.LeakyReLU(0.2,inplace=True),\n",
    "            *res_seq,\n",
    "            UpBlock(dim*4,dim*2),\n",
    "            UpBlock(dim*2,dim),\n",
    "            nn.ReflectionPad2d(3),\n",
    "            nn.Conv2d(dim,3,7,1,0),\n",
    "            nn.Tanh()     \n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.model(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Discirminator(nn.Module):\n",
    "    def __init__(self,dim = 64):\n",
    "        super(Discirminator, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3,dim,4,2,1),\n",
    "            nn.LeakyReLU(dim),\n",
    "            nn.Conv2d(dim,dim*2,4,2,1),\n",
    "            nn.InstanceNorm2d(dim*2),\n",
    "            nn.LeakyReLU(0.2,inplace=True),\n",
    "            nn.Conv2d(dim*2,dim*4,4,2,1),\n",
    "            nn.InstanceNorm2d(dim*4),\n",
    "            nn.LeakyReLU(0.2,inplace=True),\n",
    "            nn.Conv2d(dim*4,dim*8,4,2,1),\n",
    "            nn.InstanceNorm2d(dim*8),\n",
    "            nn.LeakyReLU(0.2,inplace=True),\n",
    "            nn.Conv2d(dim*8,dim*4,4,2,1),\n",
    "            nn.InstanceNorm2d(dim*4),\n",
    "            nn.LeakyReLU(0.2,inplace=True),\n",
    "            nn.Conv2d(dim*4,dim*2,4,2,1),\n",
    "            nn.InstanceNorm2d(dim*2),\n",
    "            nn.LeakyReLU(0.2,inplace=True),\n",
    "            nn.Conv2d(dim*2,1,4,2,0),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        return self.model(x)\n",
    "\n",
    "    \n",
    "class CycleGAN(nn.Module):\n",
    "    \n",
    "    def __init__(self,):\n",
    "        super(CycleGAN, self).__init__()\n",
    "        \n",
    "        self.G_SW = Generator(num_res=args.n_res).to(device)\n",
    "        self.G_WS = Generator(num_res=args.n_res).to(device)\n",
    "        self.D_S = Discirminator(args.conv_dim).to(device)\n",
    "        self.D_W = Discirminator(args.conv_dim).to(device)\n",
    "        \n",
    "        self.real_labels = torch.ones(args.batch_size,1,args.D_out_dim, args.D_out_dim ).to(device)\n",
    "        self.fake_labels = torch.zeros(args.batch_size,1,args.D_out_dim ,args.D_out_dim).to(device)\n",
    "        g_params = list(self.G_SW.parameters()) + list(self.G_WS.parameters())\n",
    "        d_params = list(self.D_S.parameters()) + list(self.D_W.parameters())\n",
    "        \n",
    "        self.G_optim = optim.Adam(g_params, lr = 0.0002, betas=(args.b1,args.b2))\n",
    "        self.D_optim = optim.Adam(d_params, lr = 0.0002, betas=(args.b1,args.b2))\n",
    "        \n",
    "      #  self.Loss = nn.MSELoss().to(device)\n",
    "        self.Loss = nn.BCELoss().to(device)\n",
    "        \n",
    "        self.D_loss_hist = []\n",
    "        self.G_loss_hist = []\n",
    "        \n",
    "        self.W_img_pool = []\n",
    "        self.S_img_pool = []\n",
    "        \n",
    "        self.L1 = nn.L1Loss()\n",
    "        \n",
    "        self.apply(self.weight_init)\n",
    "       \n",
    "    def forward(self, s_img, w_img):\n",
    "        \n",
    "        self.s_img = s_img.to(device)\n",
    "        self.w_img = w_img.to(device)  \n",
    "        \n",
    "        ############### Train D ###############\n",
    "        self.D_optim.zero_grad()\n",
    "        \n",
    "        self.g_w_img = self.G_SW(self.s_img).detach()   ### Generated Winter image\n",
    "        self.g_s_img = self.G_WS(self.w_img).detach()  ### Generated Summer image\n",
    "        \n",
    "        self.W_img_pool.append(self.g_w_img)\n",
    "        self.S_img_pool.append(self.g_s_img)\n",
    "        \n",
    "        self.W_img_pool = self.W_img_pool[-50:]\n",
    "        self.S_img_pool = self.S_img_pool[-50:]\n",
    "        \n",
    "        r_idx = torch.randint(0,len(self.W_img_pool),(2,1)).type(torch.LongTensor)\n",
    "        \n",
    "        test_w = self.W_img_pool[r_idx[0]]\n",
    "        test_s = self.S_img_pool[r_idx[1]]\n",
    "        \n",
    "        D_W_loss = self.Loss(self.D_W(test_w),self.fake_labels)\n",
    "        D_S_loss = self.Loss(self.D_S(test_s),self.fake_labels)\n",
    "        \n",
    "#         D_W_loss = self.MSE(self.D_W(self.g_w_img),self.fake_labels)\n",
    "#         D_S_loss = self.MSE(self.D_S(self.g_s_img),self.fake_labels)\n",
    "        \n",
    "        D_W_r_loss = self.Loss(self.D_W(self.w_img), self.real_labels)\n",
    "#         D_W_f_loss = self.BCE(self.D_W(self.s_img), self.fake_labels)\n",
    "#         D_S_f_loss = self.BCE(self.D_S(self.w_img), self.fake_labels)\n",
    "        D_S_r_loss = self.Loss(self.D_S(self.s_img), self.real_labels)\n",
    "        \n",
    "        \n",
    "        self.D_loss = D_W_r_loss  + D_S_r_loss + D_W_loss + D_S_loss\n",
    "        # + D_W_f_loss + D_S_f_loss\n",
    "        \n",
    "        self.D_loss_hist.append(self.D_loss.item())\n",
    "        self.D_loss.backward()\n",
    "        self.D_optim.step()\n",
    "\n",
    "        ############### Train G ###############\n",
    "        self.G_optim.zero_grad()\n",
    "        \n",
    "        # A way to skip twice forward in G ?\n",
    "        self.g_w_img = self.G_SW(self.s_img)   ### Generated Winter image\n",
    "        self.g_s_img = self.G_WS(self.w_img)  ### Generated Summer image\n",
    "        \n",
    "        G_SW_loss = self.Loss(self.D_W(self.g_w_img),self.real_labels)\n",
    "        G_WS_loss = self.Loss(self.D_S(self.g_s_img),self.real_labels)\n",
    "        \n",
    "        # Idendity Loss\n",
    "        \n",
    "        self.g_s_s_img = self.G_WS(self.s_img)\n",
    "        self.g_w_w_img = self.G_SW(self.w_img)\n",
    "        \n",
    "        identity_loss = self.L1(self.g_s_s_img, self.s_img) + self.L1(self.g_w_w_img, self.w_img)\n",
    "        \n",
    "        \n",
    "        # Reconstruct Loss\n",
    "        \n",
    "        self.g_re_s_img = self.G_WS(self.g_w_img)\n",
    "        self.g_re_w_img = self.G_SW(self.g_s_img)\n",
    "        \n",
    "        recon_loss = self.L1(self.g_re_s_img, self.s_img) + self.L1(self.g_re_w_img, self.w_img)\n",
    "        \n",
    "        self.G_loss = G_SW_loss + G_WS_loss + (recon_loss * args.lam1) + (identity_loss * args.lam2)\n",
    "        self.G_loss_hist.append(self.G_loss.item())\n",
    "        self.G_loss.backward()\n",
    "        self.G_optim.step()\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        \n",
    "    def image_save(self, step):\n",
    "        \n",
    "        training_img_path = args.img_path + \"CycleGAN_Step_\"+str(step)+\".png\"\n",
    "        save_image(torch.cat([self.s_img,self.g_w_img,self.g_re_s_img,self.w_img,self.g_s_img,self.g_re_w_img],0), training_img_path , nrow=3, normalize=True, range=(-1,1))\n",
    "        print('Image saved')\n",
    "        \n",
    "        \n",
    "    def model_save(self,step):\n",
    "        path = args.model_path + 'CycleGAN_Step_' + str(step) + '.pth'\n",
    "        torch.save({'CycleGAN':self.state_dict()}, path)\n",
    "        print('Model saved')\n",
    "        \n",
    "    def load_step_dict(self, step):\n",
    "        \n",
    "        path = args.model_path + 'CycleGAN_Step_' + str(step) + '.pth'\n",
    "        self.load_state_dict(torch.load(path, map_location=lambda storage, loc: storage)['CycleGAN'])\n",
    " \n",
    "    def plot_all_loss(self,step):\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize= (20,8))\n",
    "        plt.plot(self.G_loss_hist,label='G_loss')\n",
    "        plt.plot(self.D_loss_hist,label='D_loss')\n",
    "        plt.ylabel('Loss',fontsize=15)\n",
    "        plt.xlabel('Number of Steps',fontsize=15)\n",
    "        plt.title('Loss',fontsize=30,fontweight =\"bold\")\n",
    "        plt.legend(loc = 'upper left')\n",
    "        fig.savefig(\"CycleGAN_Loss_\"+str(step)+\".png\")\n",
    "        \n",
    "    def num_all_params(self,):\n",
    "        return sum([param.nelement() for param in self.parameters()])\n",
    "    \n",
    "    def weight_init(self,m):\n",
    "        if type(m) in [nn.Conv2d, nn.ConvTranspose2d]:\n",
    "            #nn.init.xavier_normal_(m.weight,nn.init.calculate_gain('leaky_relu',param=0.02))\n",
    "            nn.init.kaiming_normal_(m.weight,0.2,nonlinearity='leaky_relu')\n",
    "            \n",
    "cycleGAN = CycleGAN().to(device)      \n",
    "\n",
    "training_set = WeatherDataset('train', args = args)\n",
    "training_loader = DataLoader(training_set, batch_size=args.batch_size, shuffle = True,pin_memory=True)\n",
    "       \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 0\n",
    "all_steps = 1\n",
    "while epoch < args.n_epoch:\n",
    "    for i, (s_img ,w_img) in enumerate(training_loader):\n",
    "        \n",
    "        \n",
    "        start_t = time.time()\n",
    "        cycleGAN(s_img,w_img)\n",
    "        end_t = time.time()\n",
    "        \n",
    "        print('| Epoch [%d] | Step [%d] | D Loss: [%.4f] | G Loss: [%.4f] | Time: %.1fs' %\\\n",
    "              (epoch, all_steps, cycleGAN.D_loss.item(), cycleGAN.G_loss.item(),\n",
    "               end_t - start_t))\n",
    "        \n",
    "        \n",
    "        if all_steps % args.show_freq == 0: \n",
    "            fig=plt.figure(figsize=(8, 8))\n",
    "            fig.add_subplot(1,3,1)\n",
    "            plt.imshow(to_img(cycleGAN.s_img[0].cpu()*0.5+0.5))\n",
    "            fig.add_subplot(1,3,2)\n",
    "            plt.imshow(to_img(cycleGAN.g_w_img[0].cpu()*0.5+0.5))\n",
    "            fig.add_subplot(1,3,3)\n",
    "            plt.imshow(to_img(cycleGAN.g_re_s_img[0].cpu()*0.5+0.5))\n",
    "            plt.show()\n",
    "            if all_steps % args.img_save_freq ==0:\n",
    "                cycleGAN.image_save(all_steps)\n",
    "                if all_steps % args.model_save_freq == 0:\n",
    "                    cycleGAN.model_save(all_steps)\n",
    "        all_steps += 1\n",
    "    epoch +=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
